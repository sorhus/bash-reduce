#
# MapReduce framework in bash / awk / parallel
#
# Implement your own map and reduce functions in awk
# The framework will take care of the rest
#
# @author anton.sorhus@gmail.com

USAGE="Usage: bash-reduce [-m mode] [-v var=val] [-p params] mapper reducer input"
function usage() {
    printf "%s\n" "$USAGE" "Try 'bash-reduce -h' for more information."
    exit 1
}

function help() {
  printf "%s\n  * %s\n  * %s\n  * %s\n  * %s\n  * %s\n  * %s%s\n" \
    "$USAGE" \
    "[-m mode]: (s)equential, (l)ocal or (c)luster. local and cluster requires GNU parallel. cluster also requires cluster.config file. Defaults to sequential" \
    "[-v var=val]: variables passed on to the awk scripts." \
    "[-p params]: parameters passed on to parallel." \
    "mapper: file containing map function in awk." \
    "reducer: file containing reduce function in awk." \
    "input: file containing input data for the job." \
    ""
    exit 0
}

while getopts hm:v:p: OPTION; do
    case "$OPTION" in
        h)  help
            ;;
        m)  if [[ $OPTARG == "s" || $OPTARG == "sequential" ]]; then
                . core/sequential
            elif [[ $OPTARG == "l" || $OPTARG == "local" ]]; then
                . core/parallel
            elif [[ $OPTARG == "c" || $OPTARG == "cluster" ]]; then
                parallel_flags="--sshloginfile cluster.config --controlmaster --sshdelay 0.01 --progress"
                . core/parallel
            else
                usage
            fi
            ;;
        v)  awk_variables="$awk_variables -v $OPTARG"
            ;;
        p)
            parallel_flags="$parallel_flags $OPTARG"
            ;;
        ?)  usage
            ;;
   esac
done
shift $(($OPTIND - 1))

if [[ $# -ne 3 ]]; then
    usage
fi

# Default to sequential
{
    type -t execute
    rc=$?
} &> /dev/null
if [[ $rc -ne 0 ]]; then
    . core/sequential
fi

map=$(<$1)
shuffle=$(<"core/shuffle.awk")
reduce=$(<$2)
input=$3

execute "$input" "$awk_variables" "$parallel_flags"

