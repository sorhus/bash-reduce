#
# Map Reduce framework in bash / awk / GNU Parallel
#
# Implement your own map and reduce functions
# The framework will take care of the rest
#
# @author anton.sorhus@gmail.com

USAGE="Usage: bash-reduce [-m mode] mapper reducer input "
function usage() {
    printf "%s\n" "$USAGE" "Try 'bash-reduce -h' for more information."
    exit 1
}

function help() {
  printf "%s\n  * %s\n  * %s\n  * %s\n  * %s%s\n" \
    "$USAGE" \
    "mode: (s)equential, (l)ocal or (c)luster. local and cluster requires GNU parallel. cluster also requires cluster.config file. Defaults to sequential" \
    "mapper: file containing map function in awk." \
    "redcer: file containing reduce function in awk." \
    "input: file containing data for the job." \
    ""
    exit 0
}

while getopts hm: OPTION; do
    case "$OPTION" in
        h)  help
            ;;
        m)  if [[ $OPTARG == "s" || $OPTARG == "sequential" ]]; then
                . core/sequential
            elif [[ $OPTARG == "l" || $OPTARG == "local" ]]; then
                . core/parallel
            elif [[ $OPTARG == "c" || $OPTARG == "cluster" ]]; then
                . core/parallel
            else
                usage
            fi
            ;;
        ?)  usage
            ;;
   esac
done
shift $(($OPTIND - 1))

if [[ $# -ne 3 ]]; then
    usage
fi

# Default to sequential
{
    type -t execute
    rc=$?
} &> /dev/null
if [[ $rc -ne 0 ]]; then
    . core/sequential
fi

map=$(<$1)
shuffle=$(<"core/shuffle.awk")
reduce=$(<$2)

execute $3 $4

